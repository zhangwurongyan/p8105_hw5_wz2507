---
title: "hw 5"
author: "Wurongyan Zhang"
date: "11/5/2019"
output: pdf_document
header-includes:
   - \usepackage{amsmath,amsthm,amssymb}
   - \usepackage{enumitem}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## problem 1

```{r}
library(tidyverse)
library(ggplot2)
library(ggridges)
library(gridExtra)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

```{r}
colSums(is.na(iris_with_missing)) %>% 
  knitr::kable()
```


As we can see from the summary above, the data set iris_with_missing has 20 missing values in each of the 5 variables.

```{r}
na_func = function(x){
  if(is.character(x)){
    x=replace_na(x,"virginica")
  }
  else if(is.numeric(x)){
    x=replace_na(x, round(mean(x,na.rm=TRUE),digits=1))
  }
  x
}

iris=map_dfr(iris_with_missing,na_func)

```

```{r}
colSums(is.na(iris)) %>% 
  knitr::kable()
```

As we can see from the second table, there is no missing values after the function of replacement.

## problem 2

```{r,message=FALSE}
file = list.files("data")

file_data = purrr::map_dfr( str_c("./data/",file), read_csv) %>% 
 janitor::clean_names() %>% 
  mutate(file_name=file) %>% 
  mutate(file_name=str_remove(file_name,".csv")) %>% 
  separate(file_name, into = c("arm","subject_id"),sep="_") %>% arrange(arm,subject_id) %>% 
  select(subject_id, arm, everything())
  
 file_data %>% 
   knitr::kable()
```

The data frame after cleaning is shown above. 

```{r}
file_data_week=file_data %>% 
  pivot_longer(week_1:week_8,
               names_to="weeks",
               values_to = "values") %>% 
  separate(weeks, into = c("week","weeks"),sep = "_")

file_data_week %>% 
  ggplot(aes(x=weeks, y=values, group=subject_id, color=subject_id))+
  geom_line()+facet_grid(~arm) +
  labs(title = "Observations on each subject over time")
  
```

We can see from the plot that the observation values for experimental group are higher than control group on average for each person in each week on average. The values of experimental and control groups were similar at week 1 but the experimental group increased later on. Moreover, the experimental group shows increasing trend on values but the control group only fluctuate without an increasing or decreasing trend. 

## problem 3

```{r}
set.seed(100)

sim_regression= function(beta1,n=30, beta0=2,sigma_squared=50){
  sim_data= tibble(
    x=rnorm(n,mean=0, sd=1),
    y=beta0+beta1*x+rnorm(n,mean=0,sd=sqrt(sigma_squared))
  )
  
  ls_fit= lm(y~x, data=sim_data) %>% 
    broom::tidy() %>% 
    select(term, estimate, p.value) %>% 
    mutate(term=recode(term, "x"="beta1_hat")) %>% 
    filter(term=="beta1_hat") 
  
}
```

```{r}
#generate 10000 datasets from the model
sim_results=
  rerun(10000, sim_regression(beta1=0)) %>%bind_rows()
```

```{r, warning=FALSE}
#repeat above for beta1=1,2,3,4,5,6
sim_results16= 
  tibble(beta1=c(1:6)) %>% 
  mutate(model= map(beta1,~rerun(10000, sim_regression(beta1=.x)))) %>% 
  unnest() %>% 
  unnest
```

```{r,warning=FALSE}
sim_results16 %>% 
  group_by(beta1) %>% 
  summarise(total=n(),
            alpha=sum(p.value<0.05)/total) %>% ggplot(aes(y=alpha, x=beta1)) +geom_point()+geom_smooth(color="red")+labs(title = "Association between effect size and power", x= "effect size(beta 1)", y= "power")

  
```

The relationship between effect size and power is positive and at a certain point the rate of increasing will decrease. Thus increase $\beta_1$ would increase power but the increase would not be very significant when $\beta_1$ reaches certain value.

```{r}
average = 
  sim_results16 %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  group_by(beta1) %>% 
  summarise(avg_beta=mean(beta1_hat))
```

```{r}
null_reject =
  sim_results16 %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% filter(p.value<0.05) %>% group_by(beta1) %>% summarise(avg_beta_null=mean(beta1_hat))
```

```{r,message=FALSE, warning=FALSE}
plot1=average %>% ggplot(aes(x=beta1, y=avg_beta))+ geom_point()+geom_smooth()+labs(title="Relationship between estimation and true beta", x="beta 1", y="average of beta 1 hat")

plot2=null_reject %>% ggplot(aes(x=beta1, y=avg_beta_null))+ geom_point()+geom_smooth()+labs(title="Relationship between estimation and true beta on rejected data", x="beta 1", y="average of beta 1 hat")

grid.arrange(plot1,plot2, nrow = 1)

```


As we can see from those two plots, sample average of $\hat\beta_1$ for which the null is rejected is not equal to the true value of $\beta_1$, and the sample average is always higher than the true value of $\beta_1$. However, at certain point, in our example approximately when $\beta_1$ equals to 6, the sample average of $\hat\beta_1$ is approximately equals to the true value of $\beta_1$. This can be explained by the power and the increase of effective size that as true value of $\beta_1$ increases, the probability of the sample to reject the null hypothesis($\beta_1=0$) given that the null hypothesis is false increases. Therefore smaller average $\hat\beta_1$ is needed in order to reject the null hypothesis.


















